[TOC]

Kafka多副本之间如何进行数据同步？

发生异常的时候的处理机制是什么？

多副本之间的数据一致性如何解决？一致性协议又是什么？

如何确保Kafka的可靠性？Kafka中的可靠性和可用性之间的关系又如何？

本章从副本的角度切入来深挖Kafka中的数据一致性，数据可靠性等问题；

# 8.1 副本剖析

- 副本是相对于分区而言的，副本是特定分区的副本；
- 一个分区中包含多个副本，只有leader副本对外提供服务，其余follower副本在不同的broker节点中，follower副本仅负责数据同步；
- 分区中所有的副本称为AR，ISR指的是与leader副本保持同步状态的副本的集合，leader副本也是ISR中的一员；
- LEO标识每个分区中最后一条消息的下一个位置，分区中每个副本都有LEO，ISR集合中最小的LEO即为HW，俗称高水位，消费者只能拉取到HW之前的消息；

从生产者发出的一条消息首先会被写入分区的leader副本，不过还需要等待ISR集合中其他副本都同步完之后才被认为已经提交，之后才会更新分区的HW，进而消费者可以消费到这条消息；

## 8.1.1 失效副本

under-replicated分区 处于同步失效或者功能失效的副本统称为失效副本，失效副本对应的分区称为失效分区；

查看失效副本：

```shell
bin/kafka-topics.sh --zookeeper localhot:2181 --describe --topic topic-partitions --under-replicated-partitions
```



kafka 副本管理器会启动一个副本过期定时检测的定时任务，检查当前时间与副本的lestCaugthUpTimeMs差值是否大于参数 replica.lag.time.max.ms 时间指定的值；

如何判定失效副本？

1. 在一段时间内，副本没有向leader副本发起同步请求，比如副本卡住，频繁FullGC；
2. follow副本通过过慢，在一段时间内都无法赶上leader副本，比如IO开销过大；

replica.lag.max.message 在Kafka0.9以后被移除，他表示副本落后一定的数目就认为是失效的；但是该参数的设置不当会导致副本不断在同步，未同步的死循环中；

具有失效副本的分区可以从侧面反映出Kafka集群的很多问题，如果用一个指标来衡量Kafka，那么失效副本的数目必是首选。

## 8.1.2 ISR的伸缩

ISR节点的收缩：

Kafka启动的时候会启动两个与ISR相关的线程，isr-expiration 和isr-change-propagation；

isr-expiration 任务会定期检测每个分区是否需要缩减其ISR集合，这个周期和replica.lag.time.max.ms参数有关，是它的一半，默认值为5000ms；当检测到集合中有失效副本时，会收缩ISR集合，将变更后的数据记录到zookeeper节点 /brokers/topics/<topic>/partition/<partition>/state；同时将变更后的数据记录到缓存isrChangeSet中；

isr-change-propagation任务会周期性的检查isrChangeSet，发现有变更就的时候，会在zookeeper的/isr_change_notification路径下创建一个以isr_change_开头的持久顺序节点，并将信息保存到该节点上；

Kafka控制器会为/isr_change_notification添加一个watcher，当有变化时会更新相关元数据信息并向管理它的broker节点发送更新元数据的请求；

ISR集合的扩充：

当follower副本的LEO大于leader副本的HW的时候，ISR集合会扩充，之后更新/brokers/topics/<topic>/partition/<partition>/state节点和isrChangeSet，之后的步骤和收缩类似；



ISR集合的增减，会影响到整个分区的HW；

## 8.1.3 LEO和HW

消息的追加过程：

1. 生产者将消息发送至leader副本；
2. 消息追加到leader副本的本地日志文件，并且更新日志偏移量
3. follower副本向leader副本请求同步数据
4. leader副本读取本地日志文件，并更新对应拉取的follower信息；
5. leader副本将拉取到的结果返回给follower副本;
6. follower副本收到返回的拉去结果，将消息追加到本地日志文件中；

LEO和HW的变化过程：

1. 刚开始leader副本的LEO=5，所有副本的HW=0;
2. follower副本向leader副本拉取消息，同时会携带自身的LEO=0的值；
3. leader副本返回给follower副本对应的消息，计算HW=min(各follower的LEO,自身的LEO)，在响应消息中带有HW信息；
4. 两个follower副本，分别同步到LEO=3和4，计算HW=min(leader的HW,自己的LEO)；follower副本会继续向leader同步消息，并且带有自己的LEO信息；
5. leader收到follower副本的请求，和LEO=3,4的信息；更新HW的值=min(3,4,15)=3，在给follower响应的时候，会带有HW=3信息；
6. follower收到新的消息后分别更新LEO=6和8，并且更新HW=min(6/8,3)=3;



在Kafka的日志目录下有：

 recovery-point-offset-checkpoint和replication-offset-checkpoint文件分别记录了LEO和HW；Kafka会有一个定时任务将所有分区的LEO和HW写入以上两个文件中；

log-start-offset-checkpoint文件对应logStartOffset的变化；它用来标识日志文件的起始索引；



## 8.1.4 leader epoch的引入

在之前的Kafka版本中，Kafka使用的是基于HW同步机制，可能会出现数据丢失或leader副本和follower副本不一致的问题。

B是当前分区的leader副本，A是follower副本；某个时刻，B中有两个最新的消息m1m2，A分别从B中同步到了两个数据，此时A和B的LEO=2,HW=1；之后A向B请求同步，B更新HW=2；A从B的响应中更新HW=2

**场景1：数据丢失**

A在最后一次同步发出后，宕机了；在重启之后会根据之前的HW的值恢复本地的数据，此时HW=1,LEO=2,会对日志阶段，丢掉消息m2；之后A向B请求同步；

此时如果B宕机，A被选举为新的leader；B恢复以后成为follower副本，由于它的HW=2比leader副本的HW=1大，因此它会做一次日志截断，丢掉消息m2；这样一来消息就丢失了。



**场景2：数据不一致**

A为leader节点，follower副本为B，A中有两个消息m1m2,HW=LEO=2,B中有一条消息m1，并且HW和LEO都为1；

A和B都宕机了，并且B最先启动成功，为leader节点；随后B写入消息m3,将LEO和HW更新为2；此时A节点作为follower重启了，发现HW的值和leader节点一致，便不更新数据；

如此A B中的消息不一致了；



为了解决以上问题，Kafka引入了leader epoch的概念；

在需要阶段日志的时候通过leader epoch判断，而不是原来的HW；初始值为0，每当leader变化的时候就加1；每个副本的log下都有一个leader-epoch-checkpoint文件，当epoch变化时会写入该文件；文件的内容是每次的矢量 <LeaderEpoch=>StartOffset>

应对场景1：

A重启后，不是先比较HW，而是发送OffsetsForLeaderEpochRequest请求；

B为做leader收到请求，发现它的leader epoch(LE_A)和B中的不相同，那么B会查找LE_A+1对应的startOffset并返回给A；

A收到后发现之前的startOffset和当前的LEO一样=2；就不需要阶段日志；



应对场景2：

A节点发现之前的startOffset=1和当前的LEO=2不一致；就对日志截断，丢掉消息m2；



## 8.1.5 为什么不支持读写分离

读写分离的缺点：

1. 数据不一致问题 主从节点数据的同步存在一个延时的窗口，这段时间主从节点数据不一致；
2. 延时问题 主从的同步需要经历 网络-》主节点内存-》网络从节点内存，整个过程比较耗时；在Kafka这里，每次内存后还需要经历磁盘阶段，加大了延迟的时间；

主写从读 不能做到完全的负载均衡，对于写多读少的情况主节点压力很大；Kafka却可以在很大程度上实现负载均衡；



# 8.2 日志同步机制

分布式系统中，日志同步机制即要保证数据的一致性，又要保证顺序性；最简单高效的方式是，从集群中选出一个leader来负责防护力写入的顺序性，只要leader处于存活状态，follower只需要不断的同步leader中的写入顺序即可。

当leader宕机的时候，一种常见的作法是 少数服从多数，这样会要求有更多的节点保证可靠性的要求；于此相关的一致性协议有Zab，Raft等;

kafka使用的更像是微软的PacficA算法；

Kafka动态的维护ISR集合，只有ISR集合中的节点才有资格被选为leader；写入消息被所有的ISR中的副本确认后才提交；位于ISR集合中的任何副本都有资格称为leader，选举过程简单，开销低；

另外Kafka不需要宕机节点必须从本地数据日志中进行数据恢复，它允许宕机副本重新加入ISR集合，但再进入ISR集合之前需要保证自己能够重新同步完leader的所有数据；

leader的选举过程？



# 8.3 可靠性分析

可靠性不是可以用一个简单的是或否的来衡量的的指标，而一般用几个9来衡量；

- 提高可靠性方式1：

越多的副本可以保证更高的可靠性，可通常设置副本3即可；



- 可靠性方式2：

仅仅依靠副本数远远不够，需要设置acks='-1'(all)；可以最大程度的提高可靠性；



- 可靠性方式3：

消息的发送模式，有3种，发后即忘，同步和异步；为了提高可靠性就需要生产者选择同步或异步方式发送消息，并且在失败的时候，开启重试机制；配置retries参数的值大于0，参数retry.backoff.ms多次重试之间的间隔；注意，如果设置了重试，可能影响到消息的顺序，除非设置了参数 **max.in.flight.request.per.connection**=1，但这样放弃了吞吐；并且设置重试后，会带来额外的时延影响；



- 可靠性方式4：

在设置acks='-1'时，如果分区副本的ISR集合就只有leader副本，那么设置acks=-1和1的功能是一样的；因此需要设置参数 min.insync.replicas>1，保证副本数不能时1个；但如果某个时刻ISR集合真的只有1个的情况下，改正配置会导致该主题不可使用；



- 可靠性方式5：

broker端有两个参数 log.flush.interval.messages和log.flush.interval.ms用来调整同步刷盘的策略，默认时不做控制交由操作系统本身控制；这里建议不要修改，因为笔者认为可靠性不应该由同步刷盘这种机器损耗新能的操作来保障，而应该采用多副本的方式来保障；



- 可靠性方式6：

消费端的影响，设置参数enable.auto.commit=false，关闭自动提交；再手动提交的时候要保证，没有成功消费就不能提交；

对于消费端，Kafka也提供了一个可以兜底的功能，即回溯消费。



# 8.4 总结